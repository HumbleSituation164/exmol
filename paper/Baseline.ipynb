{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classification Model Code \n",
    "\n",
    "Linear Classification model using molecular scent dataset from AI crowd (https://www.aicrowd.com/challenges/learning-to-smell)\n",
    "\n",
    "Code below modified from example code given in the Classification section of \"Deep Learning for Molecules and Materials\" textbook (https://whitead.github.io/dmol-book/ml/classification.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Remember to update CUDA_VISIBLE_DEVICES')\n",
    "#For GPU nodes, edit value below based on allocated GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install packages & imports\n",
    "\n",
    "#!pip install mordred[full]  matplotlib numpy pandas seaborn jax jaxlib wandb \n",
    "\n",
    "#Code uses Weights & Biases to log results\n",
    "import wandb\n",
    "#If running code in notebook & have not yet logged in w/it into W&B, uncomment lines below\n",
    "#wandb.login()\n",
    "#%env \"WANDB_NOTEBOOK_NAME\" \"Linear Classification Model_Latest\"\n",
    "\n",
    "#Other imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import rdkit, rdkit.Chem, rdkit.Chem.Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import mordred, mordred.descriptors\n",
    "import jax.experimental.optimizers as optimizers\n",
    "import jax\n",
    "import sklearn.metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('dark',  {'xtick.bottom':True, 'ytick.left':True, 'xtick.color': '#666666', 'ytick.color': '#666666',\n",
    "                        'axes.edgecolor': '#666666', 'axes.linewidth':     0.8 , 'figure.dpi': 300})\n",
    "color_cycle = ['#1BBC9B', '#F06060', '#5C4B51', '#F3B562', '#6e5687']\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=color_cycle) \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Start a W&B run\n",
    "run = wandb.init(project='Linear_Model', entity='aseshad4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Save model inputs and hyperparameters\n",
    "config = wandb.config\n",
    "config.learning_rate = 0.04\n",
    "config.numEpochs = 1000\n",
    "config.regularization = False\n",
    "config.earlyStopping = False\n",
    "config.updatedCode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training & testing data --> file uploaded to jhub (locally stored)\n",
    "scentdata = pd.read_csv('train.csv')\n",
    "\n",
    "#Read in vocabulary text file --> this file gives the all of the scent classes used in dataset\n",
    "file = open('vocabulary.txt')\n",
    "#Create list that stores all scent classes\n",
    "scentClasses = file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make object that can compute descriptors\n",
    "calc = mordred.Calculator(mordred.descriptors, ignore_3D=True)\n",
    "# make subsample from pandas df\n",
    "allMolecules = [rdkit.Chem.MolFromSmiles(smi) for smi in scentdata.SMILES]\n",
    "\n",
    "#View one molecule to make sure code works correctly (uncomment line below to test)\n",
    "#allMolecules[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create vectors for each molecule in input data that corresponds to the classes it belongs to (scents associated with it)\n",
    "numClasses = len(scentClasses)\n",
    "numMolecules = len(allMolecules)\n",
    "labels = jnp.zeros((numMolecules, numClasses))\n",
    "for i in range(numMolecules):\n",
    "    #Create array that contains all scents associated with molecule i\n",
    "    tempScent = scentdata.SENTENCE[i].split(',')\n",
    "    #Find class index in label vector that each scent corresponds to & update label for that molecule to 1\n",
    "    for j in range(len(tempScent)):\n",
    "        #Find class index\n",
    "        classIndex = scentClasses.index(tempScent[j])\n",
    "        #Update label\n",
    "        labels = jax.ops.index_update(labels, (i,classIndex), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Test, uncomment code in this cell to test creation of label vectors\n",
    "\n",
    "##Check that y vector was created correctly (compare label vector for molecule 11 to description of molecule from datset)\n",
    "##Indices where labels has a 1 (molecule belongs to scent class with that index)\n",
    "\n",
    "#indices = jnp.argwhere(labels[11]).ravel()\n",
    "#for i in indices:\n",
    "    #scentTemp = scentClasses[i]\n",
    "    #print(scentTemp)\n",
    "#print(scentdata.SENTENCE[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute features\n",
    "features = calc.pandas(allMolecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize features\n",
    "features -= features.mean()\n",
    "features /= features.std()\n",
    "\n",
    "# we have some nans in features, likely because std was 0\n",
    "features.dropna(inplace=True, axis=1)\n",
    "\n",
    "print(f'We have {len(features.columns)} features per molecule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate testing, training, validation sets\n",
    "train_N = int(numMolecules * 0.8)\n",
    "valid_N = int(numMolecules * 0.1)\n",
    "test_N = numMolecules - train_N - valid_N\n",
    "\n",
    "batch_size = 32\n",
    "batch_idx = range(0, train_N, batch_size)\n",
    "\n",
    "train_data_labels = labels[:train_N]\n",
    "train_data_features = features[:train_N].values.astype(np.float32)\n",
    "\n",
    "valid_data_labels = labels[train_N:valid_N+train_N]\n",
    "valid_data_features = features[train_N:valid_N+train_N].values.astype(np.float32)\n",
    "\n",
    "test_data_labels = labels[valid_N+train_N:]\n",
    "test_data_features = features[valid_N+train_N:].values.astype(np.float32)\n",
    "\n",
    "print(f'Num Molecules: {numMolecules}, test_N: {test_N}, train_N: {train_N}, valid_N: {valid_N}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiLabel_classifier(x,w,b):\n",
    "    return jax.nn.sigmoid(jnp.dot(x,w) + b)\n",
    "\n",
    "def cross_entropy(yhat, y):\n",
    "    return -jnp.mean(y * jnp.log(yhat + 1e-10) + (1 - y) * jnp.log(1 - yhat + 1e-10))\n",
    "    \n",
    "def loss_wrapper(w,b,x,y):\n",
    "    yhat = multiLabel_classifier(x,w,b)\n",
    "    return jnp.mean(cross_entropy(yhat, y))\n",
    "    \n",
    "loss_grad = jax.grad(loss_wrapper, (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFunc(train_x,train_y, valid_x, valid_y):\n",
    "    loss_progress = np.zeros(config.numEpochs)\n",
    "    valid_loss_progress = np.zeros(config.numEpochs)\n",
    "    eta = config.learning_rate\n",
    "    w = np.random.normal(scale = 0.01, size = (len(features.columns),109))\n",
    "    b = np.ones(numClasses)\n",
    "    \n",
    "    for epoch in range(config.numEpochs):\n",
    "        for i in range(len(batch_idx) - 1):    \n",
    "            x = train_x[batch_idx[i]:batch_idx[i + 1]]\n",
    "            \n",
    "            y = train_y[batch_idx[i]:batch_idx[i + 1]]\n",
    "            \n",
    "            grad = loss_grad(w, b, x, y)\n",
    "            w -= eta * grad[0]\n",
    "            b -= eta * grad[1]\n",
    "            \n",
    "            loss_progress[epoch] += loss_wrapper(w, b, x, y)\n",
    "            #print(f'Training loss for batch{i}: {loss_wrapper(w, b, x, y)}')\n",
    "            currValidLoss = loss_wrapper(w,b,valid_x,valid_y)\n",
    "            #print(f'Validation loss for same step: {currValidLoss}')\n",
    "            valid_loss_progress[epoch] += currValidLoss\n",
    "  \n",
    "        numTimesLossComputed = (len(batch_idx) - 1)\n",
    "        loss_progress[epoch] = loss_progress[epoch]/numTimesLossComputed\n",
    "        valid_loss_progress[epoch] = valid_loss_progress[epoch]/numTimesLossComputed\n",
    "        print(f'Training Loss, Epoch {epoch}: {loss_progress[epoch]}')\n",
    "        print(f'Validation Loss, Epoch {epoch}: {valid_loss_progress[epoch]}')\n",
    "        \n",
    "        # 3. Log metrics over time to visualize performance (using Weights & Biases)\n",
    "        wandb.log({'Training loss': loss_progress[epoch], 'Epoch': epoch})   \n",
    "        wandb.log({\"Validation loss\": valid_loss_progress[epoch], 'Epoch': epoch})    \n",
    "        \n",
    "    resultsList = [y,w,b]\n",
    "    return resultsList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train model\n",
    "#Store w & b values from training\n",
    "results = lossFunc(train_data_features, train_data_labels, valid_data_features , valid_data_labels)\n",
    "wVals = results[1]\n",
    "bVals = results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Metrics - Accuracy (standard & competition) & AUROC (Same functions as what was used in GNN Model code)\n",
    "\n",
    "#Accuracy function where accuracy is measured as |intersection of true and predicted labels|/|union of true and predicted labels|\n",
    "def accuracy_fn(w,b, x, y): \n",
    "    yhat = multiLabel_classifier(x,w,b)\n",
    "    true_scentIndices = jnp.nonzero(y)\n",
    "    # convert from prob to hard class -> positive yhat -> yhat = 1, else 0\n",
    "    hard_yhat = np.where(yhat > 0, np.ones_like(yhat), np.zeros_like(yhat))\n",
    "    predicted_scentIndices = jnp.nonzero(hard_yhat)\n",
    "    correctlyPredicted = len(np.intersect1d(predicted_scentIndices, true_scentIndices))\n",
    "    numTrueLabels = np.size(true_scentIndices)\n",
    "\n",
    "    #Total number of labels = number of labels in union of predicted & actual/true labels set\n",
    "    ##The size of this set = Actual labels - those correctly predicted + all predicted labels\n",
    "    numPredLabels = np.size(predicted_scentIndices)\n",
    "    totalLabels = numTrueLabels - correctlyPredicted + numPredLabels\n",
    "    return correctlyPredicted/totalLabels\n",
    "\n",
    "#Competition accuracy is measured as |intersection of true and predicted labels for top 3 predictions|/|union of true and predicted labels for top 3 predictions|\n",
    "def competitionAccuracy_fn(w,b, x, y): \n",
    "    yhat = multiLabel_classifier(x,w,b)\n",
    "    numTrueLabels = jnp.count_nonzero(y) \n",
    "    true_scentIndices = jnp.nonzero(y)\n",
    "    \n",
    "    pred_sortedIndices = np.argsort(yhat)\n",
    "\n",
    "    top15Pred = pred_sortedIndices[len(pred_sortedIndices)-15:]\n",
    "    #Create array storing top 5 predictions\n",
    "    predictions = np.zeros((5,3))\n",
    "    #print(pred_sortedIndices)\n",
    "    #print(f'yhat: {yhat}')\n",
    "    for j in range(5):\n",
    "        index = 15 - (j+1)*3\n",
    "        predictions[j] = top15Pred[index:15-j*3]\n",
    "        \n",
    "    numCorrect = np.empty(5)\n",
    "    for k in range(5):\n",
    "        numCorrect[k] = len(np.intersect1d(predictions[k], true_scentIndices))\n",
    "   \n",
    "    topNumCorrect = np.amax(numCorrect)\n",
    "    topPredictionSet = np.argmax(numCorrect)\n",
    "    #Total number of labels is number of labels in union of predicted & actual/true labels set (keep only 3 true labels)\n",
    "    ##The size of this set = Predicted labels - those accounted for in actual labels + all predicted labels\n",
    "    totalLabels = 3 + (3-topNumCorrect)\n",
    "    accuracyComp = topNumCorrect/totalLabels\n",
    "    #print(f'For Molecule {i}, accuracy is: {accuracyComp}')\n",
    "    return accuracyComp, topPredictionSet\n",
    "\n",
    "#Compute accuracy\n",
    "acc = np.zeros(test_N)\n",
    "for i in range(test_N):\n",
    "    yi = test_data_labels[i]\n",
    "    xi = test_data_features[i]\n",
    "    accuracy = accuracy_fn(wVals,bVals, xi,yi)\n",
    "    #print(accuracy)\n",
    "    acc[i] = accuracy\n",
    "print(f'Overall Accuracy: {np.mean(acc)}')\n",
    "wandb.run.summary[\"Test set accuracy (standard accuracy)\"] = np.mean(acc)\n",
    "\n",
    "#Compute competition accuracy\n",
    "accCompetition = np.zeros(test_N)\n",
    "topPredSet = np.empty(test_N)\n",
    "for i in range(test_N):\n",
    "    yi = test_data_labels[i]\n",
    "    xi = test_data_features[i]\n",
    "    accuracy, topPredSet[i] = competitionAccuracy_fn(wVals,bVals, xi,yi)\n",
    "    #print(accuracy)\n",
    "    accCompetition[i] = accuracy\n",
    "print(f'Overall Accuracy (Competition): {np.mean(accCompetition)}')\n",
    "wandb.run.summary[\"Test set accuracy (competition accuracy)\"] = np.mean(accCompetition)\n",
    "\n",
    "top3Pred_correctPercent = 100*((test_N - np.count_nonzero(topPredSet))/test_N)\n",
    "print(f'Top 3 predictions were best on average (competition accuracy, regular params): {top3Pred_correctPercent}%')\n",
    "\n",
    "#Compute AUROC using sklearn\n",
    "test_yhat = np.empty((test_N, numClasses))#create empty array to store predictions on test set\n",
    "for i in range(test_N):\n",
    "    yi = test_data_labels[i]\n",
    "    xi = test_data_features[i]\n",
    "    test_yhat[i] = multiLabel_classifier(xi,wVals,bVals)\n",
    "\n",
    "occurrences = np.zeros(numClasses)\n",
    "for i in range(numClasses):\n",
    "    occurrences[i] = np.sum(labels[:,i])\n",
    "\n",
    "aurocs_scikit = []\n",
    "aurocs_omitUncommonClasses = []\n",
    "for c in range(numClasses):\n",
    "    if(np.count_nonzero(test_data_labels[:,c]) == 0):\n",
    "        print(f'Test set does not have any molecules with scent {scentClasses[c]}')\n",
    "    else:\n",
    "        #Uncomment lines below if want to plot/generate ROC curves for each label\n",
    "        #fpr, tpr, thresholds = sklearn.metrics.roc_curve(test_data_labels[:,c], test_yhat[:,c])\n",
    "        #plt.plot(fpr, tpr, '-o', label='Trained Model')\n",
    "        #plt.plot([0,1], [0, 1], label='Naive Classifier')\n",
    "        #plt.ylabel('True Positive Rate')\n",
    "        #plt.xlabel('False Positive Rate')\n",
    "        #plt.title(f'ROC Curve for {scentClasses[c]}')\n",
    "        #plt.legend()\n",
    "        #plt.show()\n",
    "        #plt.savefig(f'GNN_ROC_Curve_{scentClasses[c]}_{runName}.jpg')\n",
    "        #plt.close()\n",
    "\n",
    "        auroc = sklearn.metrics.roc_auc_score(test_data_labels[:,c], test_yhat[:,c])\n",
    "        aurocs_scikit.append(auroc)\n",
    "        if(occurrences[c] >= 30):\n",
    "            aurocs_omitUncommonClasses.append(auroc)\n",
    "            print(f'Included {scentClasses[c]}')\n",
    "        else:\n",
    "            print(f'Omitted {scentClasses[c]}')\n",
    "        print(f'AUROC for scent {scentClasses[c]}: {auroc}')\n",
    "\n",
    "mean_AUROC = np.mean(aurocs_scikit)\n",
    "mean_AUROC_omitUncommonScents = np.mean(aurocs_omitUncommonClasses)\n",
    "print(f'Mean AUROC: {mean_AUROC}')\n",
    "print(f'Mean AUROC (w/uncommon scent classes omitted): {mean_AUROC_omitUncommonScents}')\n",
    "wandb.run.summary['Mean AUROC'] = mean_AUROC\n",
    "wandb.run.summary['Mean AUROC w/uncommon scents omitted'] = mean_AUROC_omitUncommonScents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop W&B run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
